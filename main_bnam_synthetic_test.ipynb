{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T11:05:00.032315Z",
     "start_time": "2025-01-07T11:04:52.584298Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from namgcv.basemodels.bnam import BayesianNAM\n",
    "from namgcv.configs.bayesian_nam_config import DefaultBayesianNAMConfig\n",
    "from namgcv.configs.bayesian_nn_config import DefaultBayesianNNConfig\n",
    "\n",
    "import pickle"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\envs\\NAMgcv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "GREEN_RGB_COLORS = [\n",
    "    '#004c00',  # '#004e00', '#005000', '#005100', '#005300',\n",
    "    # '#005500', # '#005700', '#005900', '#005a00', '#005c00',\n",
    "    '#005e00',  # '#006000', '#006200', '#006300', '#006500',\n",
    "    # '#006700', # '#006900', '#006b00', '#006c00', '#006e00',\n",
    "    '#007000',  # '#007200', '#007400', '#007500', '#007700',\n",
    "    # '#007900', # '#007b00', '#007d00', '#007e00', '#008000',\n",
    "    '#008200',  # '#008400', '#008600', '#008800', '#008900',\n",
    "    # '#008b00', # '#008d00', '#008f00', '#009100', '#009200',\n",
    "    '#009400',  # '#009600', '#009800', '#009a00', '#009b00',\n",
    "    # '#009d00', # '#009f00', '#00a100', '#00a300', '#00a400',\n",
    "    '#00a600',  # '#00a800', '#00aa00', '#00ac00', '#00ad00',\n",
    "    # '#00af00', # '#00b100', '#00b300', '#00b500', '#00b600',\n",
    "    '#00b800',  # '#00ba00', '#00bc00', '#00be00', '#00bf00',\n",
    "    # '#00c100', # '#00c300', '#00c500', '#00c700', '#00c800',\n",
    "    '#00ca00',  # '#00cc00', '#00ce00', '#00d000', '#00d100',\n",
    "    # '#00d300', # '#00d500', '#00d700', '#00d900', '#00da00',\n",
    "    '#00dc00',  # '#00de00', '#00e000', '#00e200', '#00e300',\n",
    "    # '#00e500', # '#00e700', '#00e900', '#00eb00', '#00ec00',\n",
    "    '#00ee00',  # '#00f000', '#00f200', '#00f400', '#00f500',\n",
    "    # '#00f700', # '#00f900', '#00fb00', '#00fd00', '#00ff00'\n",
    "]\n",
    "\n",
    "\n",
    "def plot_feature_contributions(\n",
    "        num_features: dict,\n",
    "        cat_features: dict,\n",
    "        interaction_features: dict,\n",
    "        submodel_contributions: dict,\n",
    "        feature_names_mapping=None,\n",
    "        y=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots feature contributions for numerical, categorical, and interaction features.\n",
    "    Now includes a separate heatmap panel for the uncertainty of interaction features.\n",
    "\n",
    "    Args:\n",
    "        num_features (Dict[str, jnp.ndarray]):\n",
    "            Dictionary of numerical features.\n",
    "        cat_features (Dict[str, jnp.ndarray]):\n",
    "            Dictionary of categorical features.\n",
    "        interaction_features (Dict[str, jnp.ndarray]):\n",
    "            Dictionary of interaction features.\n",
    "        submodel_contributions (Dict[str, np.ndarray]):\n",
    "            Dictionary of feature contributions with keys as feature names and values\n",
    "            as numpy arrays of shape [num_samples, batch_size].\n",
    "        feature_names_mapping (Dict[str, List[str]]):\n",
    "            Optional. Mapping from feature names to category names for categorical features.\n",
    "    \"\"\"\n",
    "\n",
    "    sns.set_style(\"whitegrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    # Plot numerical features\n",
    "    if num_features:\n",
    "        num_plots = len(num_features)\n",
    "        fig, ax = plt.subplots(\n",
    "            nrows=num_plots, ncols=1,\n",
    "            figsize=(12, 6 * num_plots),\n",
    "            squeeze=False\n",
    "        )\n",
    "        ax = ax.flatten()\n",
    "        for i, (feature_name, feature_array) in enumerate(num_features.items()):\n",
    "            feature_values = np.array(feature_array).flatten()  # Convert JAX array to NumPy\n",
    "\n",
    "            contributions = submodel_contributions[feature_name]  # Shape: [num_samples, batch_size]\n",
    "            mean_contrib = contributions.mean(axis=0)  # [batch_size]\n",
    "            lower = np.percentile(contributions, 5.0, axis=0)\n",
    "            upper = np.percentile(contributions, 95.0, axis=0)\n",
    "\n",
    "            # Sort the data for a cleaner plot\n",
    "            sorted_idx = np.argsort(feature_values)\n",
    "            feature_values_sorted = feature_values[sorted_idx]\n",
    "            mean_contrib_sorted = mean_contrib[sorted_idx]\n",
    "            lower_sorted = lower[sorted_idx]\n",
    "            upper_sorted = upper[sorted_idx]\n",
    "\n",
    "            if y is not None:\n",
    "                sns.scatterplot(\n",
    "                    x=feature_values,\n",
    "                    y=y,\n",
    "                    color=GREEN_RGB_COLORS[5],\n",
    "                    label=\"Data Points\",\n",
    "                    ax=ax[i]\n",
    "                )\n",
    "\n",
    "            sns.lineplot(\n",
    "                x=feature_values_sorted,\n",
    "                y=mean_contrib_sorted,\n",
    "                color=GREEN_RGB_COLORS[0],\n",
    "                label=\"Mean Contribution\",\n",
    "                ax=ax[i]\n",
    "            )\n",
    "            ax[i].fill_between(\n",
    "                feature_values_sorted, lower_sorted, upper_sorted,\n",
    "                alpha=0.2, color=GREEN_RGB_COLORS[-1],\n",
    "                label=\"95% Credible Interval\"\n",
    "            )\n",
    "            ax[i].set_xlabel(f\"{feature_name}\", fontsize=12)\n",
    "            ax[i].set_ylabel(\"Feature Contribution\", fontsize=12)\n",
    "            ax[i].set_title(f\"Feature Contribution for {feature_name}\", fontsize=12)\n",
    "            ax[i].legend(loc='best', fontsize=12, frameon=False)\n",
    "            ax[i].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('num_feature_contributions.png')\n",
    "        plt.show()\n",
    "\n",
    "    if interaction_features:\n",
    "        num_interactions = len(interaction_features)\n",
    "        # For each interaction, we create a row with two plots:\n",
    "        # Left: Mean contribution contourf with black dashed contour lines.\n",
    "        # Right: Uncertainty (upper - lower) as a heatmap.\n",
    "        ncols = 2\n",
    "        nrows = num_interactions\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=nrows, ncols=ncols,\n",
    "            figsize=(12 * ncols, 6 * nrows),\n",
    "            squeeze=False\n",
    "        )\n",
    "\n",
    "        for idx, (interaction_name, feature_arrays) in enumerate(interaction_features.items()):\n",
    "            feature_names = interaction_name.split(\":\")\n",
    "            if len(feature_names) != 2:\n",
    "                print(\n",
    "                    f\"Skipping interaction {interaction_name}: only supports pairwise interactions.\")\n",
    "                continue\n",
    "\n",
    "            feature1_name, feature2_name = feature_names\n",
    "            feature1_values = np.array(feature_arrays[:, 0])\n",
    "            feature2_values = np.array(feature_arrays[:, 1])\n",
    "\n",
    "            contributions = submodel_contributions[interaction_name]  # [num_samples, batch_size]\n",
    "            mean_contrib = contributions.mean(axis=0)  # [batch_size]\n",
    "            lower = np.percentile(contributions, 5.0, axis=0)\n",
    "            upper = np.percentile(contributions, 95.0, axis=0)\n",
    "            uncertainty = upper - lower  # Width of the credible interval\n",
    "\n",
    "            # Create a grid for contour plot\n",
    "            num_points = 100\n",
    "            x = np.linspace(feature1_values.min(), feature1_values.max(), num_points)\n",
    "            y = np.linspace(feature2_values.min(), feature2_values.max(), num_points)\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "            from scipy.interpolate import griddata\n",
    "            points = np.stack((feature1_values, feature2_values), axis=-1)\n",
    "            grid_z_mean = griddata(points, mean_contrib, (xx, yy), method='linear')\n",
    "            grid_z_unc = griddata(points, uncertainty, (xx, yy), method='linear')\n",
    "\n",
    "            # --------------------\n",
    "            # Plot posterior mean.\n",
    "            # --------------------\n",
    "            ax_mean = axes[idx, 0]\n",
    "            cp = ax_mean.contourf(xx, yy, grid_z_mean, levels=20, cmap='Greens', alpha=0.8)\n",
    "            fig.colorbar(cp, ax=ax_mean, label='Mean Contribution')\n",
    "\n",
    "            cl = ax_mean.contour(\n",
    "                xx, yy, grid_z_mean,\n",
    "                levels=10,\n",
    "                colors='black',\n",
    "                linestyles='dashed'\n",
    "            )  # Add black dashed contour lines on top.\n",
    "            ax_mean.clabel(cl, inline=True, fontsize=10)\n",
    "            ax_mean.set_xlabel(feature1_name, fontsize=12)\n",
    "            ax_mean.set_ylabel(feature2_name, fontsize=12)\n",
    "            ax_mean.set_title(f'Mean Interaction: {feature1_name} & {feature2_name}', fontsize=14)\n",
    "            ax_mean.grid(True)\n",
    "\n",
    "            # ------------------------------\n",
    "            # Plot uncertainty as a heatmap.\n",
    "            # ------------------------------\n",
    "            ax_unc = axes[idx, 1]\n",
    "            img = ax_unc.imshow(\n",
    "                grid_z_unc,\n",
    "                origin='lower',\n",
    "                aspect='auto',\n",
    "                extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                cmap='RdPu'\n",
    "            )\n",
    "            fig.colorbar(img, ax=ax_unc, label='Uncertainty (Width of Credible Interval)')\n",
    "            ax_unc.set_xlabel(feature1_name, fontsize=12)\n",
    "            ax_unc.set_ylabel(feature2_name, fontsize=12)\n",
    "            ax_unc.set_title(f'Uncertainty: {feature1_name} & {feature2_name}', fontsize=14)\n",
    "            ax_unc.grid(False)  # No grid for heatmaps.\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('interaction_feature_contributions_uncertainty.png')\n",
    "        plt.show()"
   ],
   "id": "1184b19df1ff1a3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_synthetic_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to generate synthetic data for testing the BayesianNAM model.\n",
    "    Returns a pandas DataFrame containing the synthetic data.\n",
    "    \"\"\"\n",
    "    # ------------------\n",
    "    # Generate features.\n",
    "    # ------------------\n",
    "    np.random.seed(42)\n",
    "    n_samples = 50\n",
    "\n",
    "    numerical_1 = np.random.uniform(low=0, high=10, size=n_samples)\n",
    "    numerical_2 = np.random.uniform(low=-5, high=5, size=n_samples)\n",
    "    categorical_1 = np.random.choice(a=['A', 'B', 'C'], size=n_samples)\n",
    "    categorical_2 = np.random.choice(a=['X', 'Y', 'Z'], size=n_samples)\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    cat_1_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(categorical_1.reshape(-1, 1)).toarray(),\n",
    "        columns=[f\"Cat1_{cat}\" for cat in encoder.categories_[0]]\n",
    "    )\n",
    "    cat_2_encoded = pd.DataFrame(\n",
    "        encoder.fit_transform(categorical_2.reshape(-1, 1)).toarray(),\n",
    "        columns=[f\"Cat2_{cat}\" for cat in encoder.categories_[0]]\n",
    "    )\n",
    "\n",
    "    true_effects = {\n",
    "        \"numerical_1\": {\n",
    "            \"response\": np.sin(numerical_1),\n",
    "            \"feature\": numerical_1\n",
    "        },\n",
    "        \"numerical_2\": {\n",
    "            \"response\": numerical_2 ** 3,\n",
    "            \"feature\": numerical_2\n",
    "        },\n",
    "        \"numerical_1:numerical_2\": {\n",
    "            \"response\": numerical_1 * numerical_2,\n",
    "            \"feature\": np.stack([numerical_1, numerical_2], axis=-1)\n",
    "        }\n",
    "    }\n",
    "    noise_parameters = {\n",
    "        \"numerical_1\": {\"loc\": 0, \"scale\": 0.5, \"size\": n_samples},\n",
    "        \"numerical_2\": {\"loc\": 0, \"scale\": 10, \"size\": n_samples},\n",
    "        # \"categorical_1\": {\"a\": [-1, 0, 1], \"p\": [0.1, 0.8, 0.1], \"size\": n_samples},\n",
    "        # \"categorical_2\": {\"a\": [-1, 0, 1], \"p\": [0.1, 0.8, 0.1], \"size\": n_samples},\n",
    "    }\n",
    "    noise_parameters[\"numerical_1:numerical_2\"] = {\n",
    "            \"loc\": (\n",
    "                    noise_parameters[\"numerical_1\"][\"loc\"] *\n",
    "                    noise_parameters[\"numerical_2\"][\"loc\"]\n",
    "            ),\n",
    "            \"scale\": np.sqrt(\n",
    "                (\n",
    "                    noise_parameters[\"numerical_1\"][\"loc\"]**2 *\n",
    "                    noise_parameters[\"numerical_2\"][\"loc\"]**2\n",
    "                ) + (\n",
    "                    noise_parameters[\"numerical_1\"][\"loc\"]**2 *\n",
    "                    noise_parameters[\"numerical_2\"][\"scale\"]**2\n",
    "                ) + (\n",
    "                    noise_parameters[\"numerical_2\"][\"loc\"]**2 *\n",
    "                    noise_parameters[\"numerical_1\"][\"scale\"] ** 2\n",
    "                ) + (\n",
    "                    noise_parameters[\"numerical_1\"][\"scale\"]**2 *\n",
    "                    noise_parameters[\"numerical_2\"][\"scale\"]**2\n",
    "                )\n",
    "            ),\n",
    "            \"size\": n_samples\n",
    "        }\n",
    "    noise = {\n",
    "        \"numerical_1\": np.random.normal(**noise_parameters[\"numerical_1\"]),\n",
    "        \"numerical_2\": np.random.normal(**noise_parameters[\"numerical_2\"]),\n",
    "        # \"categorical_1\": np.random.choice(**noise_parameters[\"categorical_1\"]),\n",
    "        # \"categorical_2\": np.random.choice(**noise_parameters[\"categorical_2\"])\n",
    "        \"numerical_1:numerical_2\": np.random.normal(**noise_parameters[\"numerical_1:numerical_2\"])\n",
    "    }\n",
    "    true_effects[\"numerical_1\"][\"noisy_response\"] = (\n",
    "            true_effects[\"numerical_1\"][\"response\"] +\n",
    "            noise[\"numerical_1\"]\n",
    "    )\n",
    "    true_effects[\"numerical_2\"][\"noisy_response\"] = (\n",
    "            true_effects[\"numerical_2\"][\"response\"] +\n",
    "            noise[\"numerical_2\"]\n",
    "    )\n",
    "    true_effects[\"numerical_1:numerical_2\"][\"noisy_response\"] = (\n",
    "            true_effects[\"numerical_1:numerical_2\"][\"response\"] +\n",
    "            noise[\"numerical_1:numerical_2\"]\n",
    "    )\n",
    "\n",
    "    response = (\n",
    "            true_effects[\"numerical_1\"][\"response\"] +\n",
    "            true_effects[\"numerical_2\"][\"response\"] +\n",
    "            true_effects[\"numerical_1:numerical_2\"][\"response\"]\n",
    "    )\n",
    "\n",
    "    # --------------\n",
    "    # Plot the data.\n",
    "    # --------------\n",
    "    sns.set_style(\"whitegrid\", {\"axes.facecolor\": \".9\"})\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6*2))\n",
    "    ci_multiplier = 1.96\n",
    "\n",
    "    for i, feature_name in enumerate([\"numerical_1\", \"numerical_2\"]):\n",
    "        x_vals = true_effects[feature_name][\"feature\"]\n",
    "        y_mean = true_effects[feature_name][\"response\"]\n",
    "\n",
    "        sort_idx = np.argsort(x_vals)\n",
    "        x_sorted = x_vals[sort_idx]\n",
    "        y_sorted = y_mean[sort_idx]\n",
    "\n",
    "        y_lower = y_sorted - ci_multiplier * noise_parameters[feature_name][\"scale\"]\n",
    "        y_upper = y_sorted + ci_multiplier * noise_parameters[feature_name][\"scale\"]\n",
    "        axes[i].fill_between(x_sorted, y_lower, y_upper, color=GREEN_RGB_COLORS[-1], alpha=0.2)\n",
    "\n",
    "        sns.scatterplot(\n",
    "            x=true_effects[feature_name][\"feature\"],\n",
    "            y=true_effects[feature_name][\"noisy_response\"],\n",
    "            color=GREEN_RGB_COLORS[5],\n",
    "            label=\"Noisy Response\",\n",
    "            ax=axes[i]\n",
    "        )\n",
    "        sns.lineplot(\n",
    "            x=true_effects[feature_name][\"feature\"],\n",
    "            y=true_effects[feature_name][\"response\"],\n",
    "            color=GREEN_RGB_COLORS[0],\n",
    "            label=\"True Marginal Effect\",\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        axes[i].set_title(f\"{feature_name} Effect\", fontsize=14)\n",
    "        axes[i].set_xlabel(f\"{feature_name}\", fontsize=12)\n",
    "        axes[i].set_ylabel(\"Effect\", fontsize=12)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Plot interaction: numerical_1:numerical_2 ---\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "    feature_name = \"numerical_1:numerical_2\"\n",
    "    x1_vals = true_effects[feature_name][\"feature\"][:, 0]\n",
    "    x2_vals = true_effects[feature_name][\"feature\"][:, 1]\n",
    "    y_mean = true_effects[feature_name][\"response\"]\n",
    "    y_noisy = true_effects[feature_name][\"noisy_response\"]\n",
    "\n",
    "    x1_i = np.linspace(x1_vals.min(), x1_vals.max(), 200)\n",
    "    x2_i = np.linspace(x2_vals.min(), x2_vals.max(), 200)\n",
    "    X1_i, X2_i = np.meshgrid(x1_i, x2_i)\n",
    "    Y_i = X1_i * X2_i  # True interaction function.\n",
    "\n",
    "    Y_i_lower = Y_i - ci_multiplier * noise_parameters[feature_name][\"scale\"]\n",
    "    Y_i_upper = Y_i + ci_multiplier * noise_parameters[feature_name][\"scale\"]\n",
    "    Y_i_uncertainty = Y_i_upper - Y_i_lower\n",
    "\n",
    "    # --------------------\n",
    "    # Plot posterior mean.\n",
    "    # --------------------\n",
    "    ax_mean = axes[0]\n",
    "    cp = ax_mean.contourf(X1_i, X2_i, Y_i, levels=20, cmap='Greens', alpha=0.8)\n",
    "    fig.colorbar(cp, ax=ax_mean, label='Mean Interaction Effect')\n",
    "    cl = ax_mean.contour(X1_i, X2_i, Y_i, levels=10, colors='black', linestyles='dashed')\n",
    "    ax_mean.clabel(cl, inline=True, fontsize=10)\n",
    "    ax_mean.set_title(\"Interaction Mean Effect\", fontsize=14)\n",
    "    ax_mean.set_xlabel(\"numerical_1\", fontsize=12)\n",
    "    ax_mean.set_ylabel(\"numerical_2\", fontsize=12)\n",
    "    ax_mean.grid(True)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Plot uncertainty as a heatmap.\n",
    "    # ------------------------------\n",
    "    ax_unc = axes[1]\n",
    "    img = ax_unc.imshow(\n",
    "        Y_i_uncertainty,\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        # extent=[x1_i.min(), x1_i.max(), x2_i.min(), x2_i.max()],\n",
    "        cmap='RdPu'\n",
    "    )\n",
    "    fig.colorbar(img, ax=ax_unc, label='Uncertainty (Width of 95% CI)', orientation='vertical')\n",
    "    ax_unc.set_title(\"Interaction Uncertainty\", fontsize=14)\n",
    "    ax_unc.set_xlabel(\"numerical_1\", fontsize=12)\n",
    "    ax_unc.set_ylabel(\"numerical_2\", fontsize=12)\n",
    "    ax_unc.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # -------\n",
    "    # Return.\n",
    "    # -------\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                data={\n",
    "                    'numerical_1': numerical_1,\n",
    "                    'numerical_2': numerical_2,\n",
    "                }\n",
    "            ),\n",
    "            # cat_1_encoded,\n",
    "            # cat_2_encoded,\n",
    "            pd.DataFrame(data={'Response': response})\n",
    "        ], axis=1\n",
    "    )"
   ],
   "id": "4615dc70027d8328"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data preparation.\n",
   "id": "2e7671e530b25062"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = get_synthetic_data()\n",
    "\n",
    "X = data.drop(columns=['Response'])\n",
    "y = data['Response']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "y_train = scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test = scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "input_dim = X_train_scaled.shape[1]"
   ],
   "id": "8fe641e727acaef3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training.",
   "id": "d6dc5298ecc9e495"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "inference_method = 'mcmc'\n",
    "model = BayesianNAM(\n",
    "    cat_feature_info={},\n",
    "    num_feature_info={\n",
    "        feature_name: {\n",
    "            \"input_dim\": 1,\n",
    "            \"output_dim\": 1\n",
    "        } for feature_name in X_train.columns\n",
    "    },\n",
    "    num_classes=1,\n",
    "    config=DefaultBayesianNAMConfig(),\n",
    "    subnetwork_config=DefaultBayesianNNConfig()\n",
    ")\n",
    "model_dir = f\"bnam_numpyro_{inference_method}.pkl\"\n",
    "try:\n",
    "    model.load_model(filepath=model_dir)\n",
    "except FileNotFoundError:\n",
    "    model.train_model(\n",
    "        num_features={\n",
    "            feature_name: jnp.array(\n",
    "                X_train_scaled[:, col_idx]\n",
    "            ) for col_idx, feature_name in enumerate(X_train.columns)\n",
    "        },\n",
    "        cat_features={},\n",
    "        target=jnp.array(y_train),\n",
    "        inference_method=inference_method\n",
    "    )\n",
    "    # model.save_model(filepath=model_dir)\n",
    "\n",
    "num_features = {\n",
    "    feature_name: jnp.array(\n",
    "        X_test_scaled[:, col_idx]\n",
    "    ) for col_idx, feature_name in enumerate(X_test.columns)\n",
    "}\n",
    "cat_features = {}\n",
    "y_pred, y_std, submodel_contributions = model.predict(\n",
    "    num_features=num_features,\n",
    "    cat_features=cat_features,\n",
    ")\n"
   ],
   "id": "108096906a37f983"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Results analysis.",
   "id": "eca80248adb0578a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "interaction_feature_information = {}\n",
    "all_features = {**num_features, **cat_features}\n",
    "for interaction_name in submodel_contributions.keys():\n",
    "    if \":\" not in interaction_name:\n",
    "        continue\n",
    "\n",
    "    feature_names = interaction_name.split(\":\")\n",
    "    interaction_feature_information[interaction_name] = jnp.concatenate(\n",
    "        [jnp.expand_dims(all_features[name], axis=-1) for name in feature_names],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "plot_feature_contributions(\n",
    "    num_features=num_features,\n",
    "    cat_features=cat_features,\n",
    "    interaction_features=interaction_feature_information,\n",
    "    submodel_contributions=submodel_contributions,\n",
    "    y=y_test\n",
    ")\n",
    "\n",
    "sns.set_style(\"whitegrid\", {\"axes.facecolor\": \".9\"})\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "sns.scatterplot(\n",
    "    x=y_test,\n",
    "    y=y_pred,\n",
    "    color=GREEN_RGB_COLORS[0],\n",
    "    label=\"Predictions\",\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel(\"Actuals\", fontsize=12)\n",
    "ax.set_ylabel(\"Predictions\", fontsize=12)\n",
    "ax.set_title(\n",
    "    f\"Predictions vs. Actuals | MSE: {np.mean((y_test - y_pred) ** 2):.4f}\",\n",
    "    fontsize=12\n",
    ")\n",
    "ax.legend(loc='best', fontsize=12, frameon=False)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pass"
   ],
   "id": "5d9e1b91df2d6d00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
